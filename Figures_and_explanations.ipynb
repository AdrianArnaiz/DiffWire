{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-dataset\" data-toc-modified-id=\"Import-dataset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import dataset</a></span></li><li><span><a href=\"#Embeddings-CTNet-(same-for-other-models)-Conv2_layer----All-graphs\" data-toc-modified-id=\"Embeddings-CTNet-(same-for-other-models)-Conv2_layer----All-graphs-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Embeddings CTNet (same for other models) Conv2_layer -- All graphs</a></span><ul class=\"toc-item\"><li><span><a href=\"#Modificar-modelo-para-sacar-cosas\" data-toc-modified-id=\"Modificar-modelo-para-sacar-cosas-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Modificar modelo para sacar cosas</a></span></li></ul></li><li><span><a href=\"#Table-of-percentage-of-added/removed-edges\" data-toc-modified-id=\"Table-of-percentage-of-added/removed-edges-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Table of percentage of added/removed edges</a></span></li><li><span><a href=\"#Rewiring-plots-and\" data-toc-modified-id=\"Rewiring-plots-and-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Rewiring plots and</a></span></li><li><span><a href=\"#All-graphs-embedding\" data-toc-modified-id=\"All-graphs-embedding-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>All graphs embedding</a></span></li><li><span><a href=\"#DIGL\" data-toc-modified-id=\"DIGL-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>DIGL</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para CTNet, MinCutNet, GapNet and DIGL (4 figuras de cada task): \n",
    "- [ ] Embeddings de un grafo solo *conv2* -> dispersión\n",
    "    * Seleccionar grafo que tenga buen accuracy y cambie más la predicción respecto a baseline\n",
    "    * Train vs test\n",
    "- [X] Embeddings de to los grafos (después del readout) pa plotearlo todos juntos y que se vea la separación entre clases\n",
    "    * Train vs test\n",
    "- [ ] Grafo con ejes con peso CT matrix en CTNet\n",
    "    * Seleccionar grafo que tenga buen accuracy y cambie más la predicción respecto a baseline\n",
    "    * Train vs test\n",
    "- [ ] Grafo con ejes adjacency modificada en GapNet\n",
    "    * Seleccionar grafo que tenga buen accuracy y cambie más la predicción respecto a baseline\n",
    "    * Train vs test\n",
    "- [X] Datos sobre grafos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:17:42.166955Z",
     "start_time": "2022-05-15T20:17:42.123965Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:17:45.516004Z",
     "start_time": "2022-05-15T20:17:42.919078Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from nets import CTNet, GAPNet\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "from transform_features import FeatureDegree\n",
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import DenseGraphConv\n",
    "from torch_geometric.utils import to_dense_batch, to_dense_adj\n",
    "from CT_layer import dense_CT_rewiring\n",
    "from MinCut_Layer import dense_mincut_pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:17:46.312142Z",
     "start_time": "2022-05-15T20:17:46.179493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:17:47.058657Z",
     "start_time": "2022-05-15T20:17:46.936956Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(modelo, loader, device):\n",
    "    modelo.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        pred, mc_loss, o_loss = modelo(data.x, data.edge_index, data.batch)\n",
    "        loss = F.nll_loss(pred, data.y.view(-1)) + mc_loss + o_loss\n",
    "        correct += pred.max(dim=1)[1].eq(data.y.view(-1)).sum().item()\n",
    "\n",
    "    return loss, correct / len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:17:48.039127Z",
     "start_time": "2022-05-15T20:17:47.897323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset = TUDataset(root=\\'data_colab/TUDataset\\',name=\"MUTAG\")\\nBATCH_SIZE = 32\\nnum_of_centers = 17'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TUDataset(root='data_colab/TUDataset',name=\"REDDIT-BINARY\", pre_transform=FeatureDegree(), use_node_attr=True)\n",
    "BATCH_SIZE = 16\n",
    "num_of_centers = 420\n",
    "\n",
    "\"\"\"dataset = TUDataset(root='data_colab/TUDataset',name=\"MUTAG\")\n",
    "BATCH_SIZE = 32\n",
    "num_of_centers = 17\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:17:48.819954Z",
     "start_time": "2022-05-15T20:17:48.685539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: REDDIT-BINARY(2000):\n",
      "====================\n",
      "Number of graphs: 2000\n",
      "Number of features: 1, 1, 1\n",
      "Number of classes: 2\n",
      "\n",
      "Data(edge_index=[2, 480], y=[1], x=[218, 1], num_nodes=218)\n",
      "=============================================================\n",
      "Number of nodes: 218\n",
      "Number of edges: 480\n",
      "Average node degree: 2.20\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n",
      "REDDIT-BINARY(2000)\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}, {dataset.num_node_features}, {dataset.num_node_attributes}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "print()\n",
    "datum = dataset[0]  # Get the first graph object.\n",
    "print(datum)\n",
    "print('=============================================================')\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {datum.num_nodes}')\n",
    "print(f'Number of edges: {datum.num_edges}')\n",
    "print(f'Average node degree: {datum.num_edges / datum.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {datum.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {datum.has_self_loops()}')\n",
    "print(f'Is undirected: {datum.is_undirected()}')\n",
    "\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:17:49.641668Z",
     "start_time": "2022-05-15T20:17:49.518334Z"
    }
   },
   "outputs": [],
   "source": [
    "train_indices, test_indices = train_test_split(list(range(len(dataset.data.y))), test_size=0.2, stratify=dataset.data.y,\n",
    "                                random_state=12345, shuffle=True)\n",
    "\n",
    "train_indices.extend(test_indices)\n",
    "new_order = train_indices\n",
    "dataset = dataset[new_order]\n",
    "loader =  DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T11:31:57.691542Z",
     "start_time": "2022-05-15T11:31:57.562851Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T11:29:57.627913Z",
     "start_time": "2022-05-15T11:29:57.461359Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T11:31:07.520564Z",
     "start_time": "2022-05-15T11:31:07.383931Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings CTNet (same for other models) Conv2_layer -- All graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probar modelo guardaddo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:17:51.831675Z",
     "start_time": "2022-05-15T20:17:51.713985Z"
    }
   },
   "outputs": [],
   "source": [
    "if dataset.name=='REDDIT-BINARY':\n",
    "    modelito = \"models/REDDIT-BINARY_CTNet_iter0.pth\"\n",
    "elif dataset.name=='MUTAG':\n",
    "    modelito = \"models/MUTAG_CTNet_iter0.pth\"\n",
    "else:\n",
    "    raise Exception('No model for that dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-14T18:20:46.339549Z",
     "start_time": "2022-05-14T18:20:46.230815Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T18:49:22.096946Z",
     "start_time": "2022-05-15T18:49:21.967261Z"
    }
   },
   "outputs": [],
   "source": [
    "#Epoch: 059, Train Loss: 165.455, Train Acc: 0.711, Test Loss: 150.841, Test Acc: 0.750\n",
    "model =  CTNet(dataset.num_features, dataset.num_classes, k_centers=num_of_centers).to(device)\n",
    "model.load_state_dict(torch.load(modelito, map_location=torch.device(device)))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T18:49:25.961903Z",
     "start_time": "2022-05-15T18:49:25.766320Z"
    }
   },
   "outputs": [],
   "source": [
    "loss, acc = test(model, loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T18:49:26.711866Z",
     "start_time": "2022-05-15T18:49:26.539328Z"
    }
   },
   "outputs": [],
   "source": [
    "loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modificar modelo para sacar cosas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T11:38:36.098817Z",
     "start_time": "2022-05-15T11:38:35.983128Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo y Test modificado que coja los embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T18:40:52.360276Z",
     "start_time": "2022-05-15T18:40:52.241503Z"
    }
   },
   "outputs": [],
   "source": [
    "class CTNet_embedding(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k_centers, hidden_channels=32):\n",
    "        super(CTNet_embedding, self).__init__()\n",
    "    \n",
    "        self.lin1 = Linear(in_channels, hidden_channels)\n",
    "        num_of_centers1 =  k_centers # k1 #order of number of nodes\n",
    "        self.pool1 = Linear(hidden_channels, num_of_centers1)\n",
    "        #self.CT = CTLayer()\n",
    "        self.conv1 = DenseGraphConv(hidden_channels, hidden_channels)\n",
    "        num_of_centers2 =  16 # k2 #mincut \n",
    "        self.pool2 = Linear(hidden_channels, num_of_centers2)\n",
    "        #self.MinCut = MinCutLayer()\n",
    "        self.conv2 = DenseGraphConv(hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, hidden_channels) # MLPs towards out \n",
    "        self.lin3 = Linear(hidden_channels, out_channels)\n",
    "        \n",
    "        self.readout = torch.zeros(0)#Creamos la variable que recoge nuestros embedings\n",
    "\n",
    "    def forward(self, x, edge_index, batch):    # x torch.Size([N, N]),  data.batch  torch.Size([661])  \n",
    "        # Make all adjacencies of size NxN \n",
    "        adj = to_dense_adj(edge_index, batch) # adj torch.Size(B, N, N])\n",
    "        # Make all x_i of size N=MAX(N1,...,N20), e.g. N=40:\n",
    "        x, mask = to_dense_batch(x, batch) # x torch.Size([20, N, 32]) ; mask torch.Size([20, N]) batch_size=20\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        # First mincut pool for computing Fiedler adn rewire \n",
    "        s1  = self.pool1(x)\n",
    "\n",
    "        if torch.isnan(adj).any():\n",
    "            print(\"adj nan\")\n",
    "        if torch.isnan(x).any():\n",
    "            print(\"x nan\")\n",
    "        \n",
    "        # CT REWIRING\n",
    "        adj, CT_loss, ortho_loss1 = dense_CT_rewiring(x, adj, s1, mask) # out: x torch.Size([20, N, F'=32]),  adj torch.Size([20, N, N])\n",
    "\n",
    "        # CONV1: Now on x and rewired adj: \n",
    "        x = self.conv1(x, adj) #out: x torch.Size([20, N, F'=32])\n",
    "\n",
    "        # MLP of k=16 outputs s\n",
    "        s2 = self.pool2(x) # s torch.Size([20, N, k])\n",
    "        \n",
    "        # MINCUT_POOL\n",
    "        x, adj, mincut_loss2, ortho_loss2 = dense_mincut_pool(x, adj, s2, mask) # out x torch.Size([20, k=16, F'=32]),  adj torch.Size([20, k2=16, k2=16])\n",
    "\n",
    "        # CONV2: Now on coarsened x and adj: \n",
    "        x = self.conv2(x, adj) #out x torch.Size([20, 16, 32])\n",
    "        \n",
    "        # Readout for each of the 20 graphs\n",
    "        x = x.sum(dim=1) # x torch.Size([20, 32])\n",
    "        \n",
    "        #Queremos esta x, por lo que nos la guardamos\n",
    "        self.readout = x.clone()\n",
    "        \n",
    "        # Final MLP for graph classification: hidden channels = 32\n",
    "        x = F.relu(self.lin2(x)) # x torch.Size([20, 32])\n",
    "        x = self.lin3(x) #x torch.Size([20, 2])\n",
    "        #print(x.shape)\n",
    "        \n",
    "        CT_loss = CT_loss + ortho_loss1\n",
    "        mincut_loss = mincut_loss2 + ortho_loss2\n",
    "        return F.log_softmax(x, dim=-1), CT_loss, mincut_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T18:40:53.105842Z",
     "start_time": "2022-05-15T18:40:52.938717Z"
    }
   },
   "outputs": [],
   "source": [
    "model =  CTNet_embedding(dataset.num_features, dataset.num_classes, k_centers=num_of_centers).to(device)\n",
    "model.load_state_dict(torch.load(modelito, map_location=torch.device(device)))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T18:40:53.849854Z",
     "start_time": "2022-05-15T18:40:53.681305Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_embedd(modelo, loader, device):\n",
    "    test_predictions = []\n",
    "    test_labels = []\n",
    "    modelo.eval()\n",
    "    correct = 0\n",
    "    for i,data in enumerate(loader):\n",
    "        data = data.to(device)\n",
    "        pred, mc_loss, o_loss = modelo(data.x, data.edge_index, data.batch)\n",
    "        loss = F.nll_loss(pred, data.y.view(-1)) + mc_loss + o_loss\n",
    "        \n",
    "        correct += pred.max(dim=1)[1].eq(data.y.view(-1)).sum().item()\n",
    "        test_predictions.extend(pred.max(dim=1)[1].tolist())\n",
    "        test_labels.extend(data.y.detach().cpu().numpy())\n",
    "        \n",
    "        if i == 0:\n",
    "            test_embeddings = modelo.readout\n",
    "        else:\n",
    "            test_embeddings = torch.cat((test_embeddings,modelo.readout.detach()), 0)\n",
    "        \n",
    "        #print(modelo.emb.shape)\n",
    "    return loss.detach().cpu(), correct / len(loader.dataset), test_embeddings, test_labels, test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluar modelo para chequear comportamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T18:40:54.720171Z",
     "start_time": "2022-05-15T18:40:54.535213Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "loss, acc, test_embeddings, test_labels, test_predictions = test_embedd(model, loader, device)\n",
    "test_embeddings = test_embeddings.detach().cpu()\n",
    "print('Embedding shape:',test_embeddings.shape, test_embeddings.device)\n",
    "print('Dataset size:',len(test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T18:40:55.404353Z",
     "start_time": "2022-05-15T18:40:55.235792Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Embedding shape:',test_embeddings.shape, test_embeddings.device)\n",
    "print('Dataset size:',len(test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T18:40:56.100588Z",
     "start_time": "2022-05-15T18:40:55.945172Z"
    }
   },
   "outputs": [],
   "source": [
    "loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T11:26:08.413452Z",
     "start_time": "2022-05-15T11:26:08.304709Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T11:24:38.556014Z",
     "start_time": "2022-05-15T11:24:38.429353Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotear embeddings con sus correspondientes etiquetas y predicciones en sus correspondiente partición.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T11:39:06.781738Z",
     "start_time": "2022-05-15T11:39:06.636119Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T11:39:09.320248Z",
     "start_time": "2022-05-15T11:39:09.148412Z"
    }
   },
   "outputs": [],
   "source": [
    "train_indices, test_indices = train_test_split(list(range(len(dataset.data.y))), test_size=0.2, stratify=dataset.data.y,\n",
    "                                random_state=12345, shuffle=True)\n",
    "#train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "#test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    "e = np.array(test_embeddings)\n",
    "p = np.array(test_predictions)\n",
    "l = np.array(test_labels)\n",
    "print('Acc:',(np.sum(p == l)/len(p))*100)\n",
    "\n",
    "e_train = e[train_indices]\n",
    "e_test  = e[test_indices]\n",
    "lab_train = l[train_indices]\n",
    "lab_test  = l[test_indices]\n",
    "pred_train = p[train_indices]\n",
    "pred_test  = p[test_indices]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print_embeddings(e_train, e_test, lab_train, lab_test, pred_train, pred_test, len(set(l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T17:58:17.523147Z",
     "start_time": "2022-05-15T17:58:17.310013Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import cm\n",
    "\n",
    "def print_embeddings(train_embedd, test_embedd, train_labels, test_labels, train_pred, test_pred, num_categories):\n",
    "    \n",
    "    train_embedd = np.array(train_embedd)\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_embedd = np.array(test_embedd)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    tsne = TSNE(n_components=2, verbose=0, perplexity=80, learning_rate=800)\n",
    "    tsne_results = tsne.fit_transform(np.vstack([train_embedd,test_embedd]))\n",
    "    \n",
    "    train_embedd_2dim = tsne_results[:len(train_embedd)]\n",
    "    test_embedd_2dim = tsne_results[len(train_embedd):]\n",
    "\n",
    "    cmap = cm.get_cmap('Set2')\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(17,8))\n",
    "\n",
    "    for lab in range(num_categories):\n",
    "        train_indices_lab = train_labels == lab\n",
    "        test_indices_lab = test_labels == lab\n",
    "        \n",
    "        ax[0].scatter(train_embedd_2dim[train_indices_lab,0], train_embedd_2dim[train_indices_lab,1],\n",
    "                   c=np.array(cmap(lab)).reshape(1,4), label = f\"{lab}_train\" ,alpha=0.5, marker ='o')\n",
    "        #ax[0].scatter(test_embedd_2dim[test_indices_lab,0], test_embedd_2dim[test_indices_lab,1],\n",
    "        #           c=np.array(cmap(lab)).reshape(1,4), label = f\"{lab}_test\" ,alpha=0.5, marker ='x')\n",
    "        ax[0].set_title('Real Label')\n",
    "        \n",
    "    for lab in range(num_categories):\n",
    "        train_indices_pred = train_pred == lab\n",
    "        test_indices_pred = test_pred == lab\n",
    "        \n",
    "        acc_test = (np.sum(test_pred == test_labels)/len(test_labels))*100\n",
    "        acc_train = (np.sum(train_pred == train_labels)/len(train_pred))*100\n",
    "        \n",
    "        #ax[1].scatter(train_embedd_2dim[train_indices_pred,0], train_embedd_2dim[train_indices_pred,1],\n",
    "        #           c=np.array(cmap(lab)).reshape(1,4), label = f\"{lab}_train\" ,alpha=0.5, marker ='o')\n",
    "        ax[1].scatter(test_embedd_2dim[test_indices_pred,0], test_embedd_2dim[test_indices_pred,1],\n",
    "                   c=np.array(cmap(lab)).reshape(1,4), label = f\"{lab}_test\" ,alpha=0.5, marker ='x')\n",
    "        ax[1].set_title(f'Predicted\\n$Acc_{{train}}={acc_train:.1f}$ - $Acc_{{test}}={acc_test:.1f}$')\n",
    "\n",
    "        ax[1].legend(fontsize='large', markerscale=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T11:39:36.392428Z",
     "start_time": "2022-05-15T11:39:16.168843Z"
    }
   },
   "outputs": [],
   "source": [
    "print_embeddings(e_train, e_test, lab_train, lab_test, pred_train, pred_test, len(set(l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T18:13:45.978047Z",
     "start_time": "2022-05-15T18:13:45.826572Z"
    }
   },
   "outputs": [],
   "source": [
    "assert 1==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of percentage of added/removed edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:17:58.277574Z",
     "start_time": "2022-05-15T20:17:58.150206Z"
    }
   },
   "outputs": [],
   "source": [
    "class CTNet_adj_rw(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k_centers, hidden_channels=32):\n",
    "        super(CTNet_adj_rw, self).__init__()\n",
    "    \n",
    "        self.lin1 = Linear(in_channels, hidden_channels)\n",
    "        num_of_centers1 =  k_centers # k1 #order of number of nodes\n",
    "        self.pool1 = Linear(hidden_channels, num_of_centers1)\n",
    "        #self.CT = CTLayer()\n",
    "        self.conv1 = DenseGraphConv(hidden_channels, hidden_channels)\n",
    "        num_of_centers2 =  16 # k2 #mincut \n",
    "        self.pool2 = Linear(hidden_channels, num_of_centers2)\n",
    "        #self.MinCut = MinCutLayer()\n",
    "        self.conv2 = DenseGraphConv(hidden_channels, hidden_channels)\n",
    "        self.lin2 = Linear(hidden_channels, hidden_channels) # MLPs towards out \n",
    "        self.lin3 = Linear(hidden_channels, out_channels)\n",
    "        \n",
    "        self.new_adj = torch.zeros(0)#Creamos la variable que recoge nuestros embedings\n",
    "\n",
    "    def forward(self, x, edge_index, batch):    # x torch.Size([N, N]),  data.batch  torch.Size([661])  \n",
    "        # Make all adjacencies of size NxN \n",
    "        adj = to_dense_adj(edge_index, batch) # adj torch.Size(B, N, N])\n",
    "        # Make all x_i of size N=MAX(N1,...,N20), e.g. N=40:\n",
    "        x, mask = to_dense_batch(x, batch) # x torch.Size([20, N, 32]) ; mask torch.Size([20, N]) batch_size=20\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        # First mincut pool for computing Fiedler adn rewire \n",
    "        s1  = self.pool1(x)\n",
    "\n",
    "        if torch.isnan(adj).any():\n",
    "            print(\"adj nan\")\n",
    "        if torch.isnan(x).any():\n",
    "            print(\"x nan\")\n",
    "        \n",
    "        # CT REWIRING\n",
    "        adj, CT_loss, ortho_loss1 = dense_CT_rewiring(x, adj, s1, mask) # out: x torch.Size([20, N, F'=32]),  adj torch.Size([20, N, N])\n",
    "\n",
    "        self.new_adj = adj.clone()\n",
    "        # CONV1: Now on x and rewired adj: \n",
    "        x = self.conv1(x, adj) #out: x torch.Size([20, N, F'=32])\n",
    "\n",
    "        # MLP of k=16 outputs s\n",
    "        s2 = self.pool2(x) # s torch.Size([20, N, k])\n",
    "        \n",
    "        # MINCUT_POOL\n",
    "        x, adj, mincut_loss2, ortho_loss2 = dense_mincut_pool(x, adj, s2, mask) # out x torch.Size([20, k=16, F'=32]),  adj torch.Size([20, k2=16, k2=16])\n",
    "\n",
    "        # CONV2: Now on coarsened x and adj: \n",
    "        x = self.conv2(x, adj) #out x torch.Size([20, 16, 32])\n",
    "        \n",
    "        # Readout for each of the 20 graphs\n",
    "        x = x.sum(dim=1) # x torch.Size([20, 32])\n",
    "        \n",
    "        # Final MLP for graph classification: hidden channels = 32\n",
    "        x = F.relu(self.lin2(x)) # x torch.Size([20, 32])\n",
    "        x = self.lin3(x) #x torch.Size([20, 2])\n",
    "        #print(x.shape)\n",
    "        \n",
    "        CT_loss = CT_loss + ortho_loss1\n",
    "        mincut_loss = mincut_loss2 + ortho_loss2\n",
    "        return F.log_softmax(x, dim=-1), CT_loss, mincut_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:51:48.558211Z",
     "start_time": "2022-05-15T20:51:48.355186Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.utils import dense_to_sparse, to_dense_adj\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_get_pct_modified_edges(modelo, loader, device):\n",
    "    \n",
    "    test_predictions = []\n",
    "    test_labels = []\n",
    "    added_edges_pct = []\n",
    "    removed_edges_pct = []\n",
    "    \n",
    "    modelo.eval()\n",
    "    correct = 0\n",
    "    \n",
    "    for i,data in enumerate(loader):\n",
    "        data = data.to(device)\n",
    "        pred, mc_loss, o_loss = modelo(data.x, data.edge_index, data.batch)\n",
    "        loss = F.nll_loss(pred, data.y.view(-1)) + mc_loss + o_loss\n",
    "        correct += pred.max(dim=1)[1].eq(data.y.view(-1)).sum().item()\n",
    "        test_predictions.extend(pred.max(dim=1)[1].tolist())\n",
    "        test_labels.extend(data.y.detach().cpu().numpy())\n",
    "        \n",
    "        original_adjs = to_dense_adj(data.edge_index, data.batch).detach().cpu().numpy()\n",
    "        adj_rw = modelo.new_adj.detach().clone().cpu().numpy()\n",
    "        original = np.count_nonzero(original_adjs, axis=(1,2))\n",
    "        removed = np.count_nonzero(original_adjs, axis=(1,2))-np.count_nonzero(original_adjs*adj_rw, axis=(1,2))\n",
    "        added = np.count_nonzero(adj_rw, axis=(1,2)) - (original-removed)\n",
    "        removed_pct = (removed/original)*100\n",
    "        added_pct =(added/original)*100\n",
    "        added_edges_pct.extend(added_pct)\n",
    "        removed_edges_pct.extend(removed_edges_pct)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "    return loss.detach().cpu(), correct/len(test_labels), added_edges_pct, removed_edges_pct, test_labels, test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:51:52.315099Z",
     "start_time": "2022-05-15T20:51:50.102588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CTNet_adj_rw(\n",
       "  (lin1): Linear(in_features=1, out_features=32, bias=True)\n",
       "  (pool1): Linear(in_features=32, out_features=420, bias=True)\n",
       "  (conv1): DenseGraphConv(32, 32)\n",
       "  (pool2): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (conv2): DenseGraphConv(32, 32)\n",
       "  (lin2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (lin3): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  CTNet_adj_rw(dataset.num_features, dataset.num_classes, k_centers=num_of_centers).to(device)\n",
    "model.load_state_dict(torch.load(modelito, map_location=torch.device(device)))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:51:54.566698Z",
     "start_time": "2022-05-15T20:51:54.196463Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 236.00 MiB (GPU 0; 6.00 GiB total capacity; 4.58 GiB already allocated; 0 bytes free; 4.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13876/2746259668.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_aditions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_removals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_get_pct_modified_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0madj_rw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madj_rw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ADJ shape:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0madj_rw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madj_rw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Dataset size:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\geometric\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13876/527996135.py\u001b[0m in \u001b[0;36mtest_get_pct_modified_edges\u001b[1;34m(modelo, loader, device)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmc_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmc_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mo_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\geometric\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13876/526501497.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# CT REWIRING\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0madj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCT_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mortho_loss1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdense_CT_rewiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# out: x torch.Size([20, N, F'=32]),  adj torch.Size([20, N, N])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_adj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Personal\\ELLIS\\PhD\\code\\GraphRewiring\\CT_layer.py\u001b[0m in \u001b[0;36mdense_CT_rewiring\u001b[1;34m(x, adj, s, mask)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;31m# Calculate CT_dist (distance matrix)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0mCT_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# [20, N, k], [20, N, k]-> [20,N,N]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;31m#print(\"CT_dist\",CT_dist)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\geometric\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36mcdist\u001b[1;34m(x1, x2, p, compute_mode)\u001b[0m\n\u001b[0;32m   1151\u001b[0m             cdist, (x1, x2), x1, x2, p=p, compute_mode=compute_mode)\n\u001b[0;32m   1152\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'use_mm_for_euclid_dist_if_necessary'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1153\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[attr-defined]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1154\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcompute_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'use_mm_for_euclid_dist'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[attr-defined]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 236.00 MiB (GPU 0; 6.00 GiB total capacity; 4.58 GiB already allocated; 0 bytes free; 4.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "loss, acc, edge_aditions, edge_removals, test_labels, test_predictions = test_get_pct_modified_edges(model, loader, device)\n",
    "adj_rw = adj_rw.detach().cpu()\n",
    "print('ADJ shape:',adj_rw.shape, adj_rw.device)\n",
    "print('Dataset size:',len(test_predictions))\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:21:45.587908Z",
     "start_time": "2022-05-15T20:21:45.587908Z"
    }
   },
   "outputs": [],
   "source": [
    "p = np.array(test_predictions)\n",
    "l = np.array(test_labels)\n",
    "print('Acc:',(np.sum(p == l)/len(p))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:21:45.595887Z",
     "start_time": "2022-05-15T20:21:45.595887Z"
    }
   },
   "outputs": [],
   "source": [
    "np.mean(edge_aditions), np.std(edge_aditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:21:45.604862Z",
     "start_time": "2022-05-15T20:21:45.604862Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(edge_aditions, bins=int(np.sqrt(len(edge_aditions))));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:21:45.614835Z",
     "start_time": "2022-05-15T20:21:45.614835Z"
    }
   },
   "outputs": [],
   "source": [
    "np.mean(edge_removals), np.std(edge_removals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:21:45.622816Z",
     "start_time": "2022-05-15T20:21:45.622816Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(edge_removals, bins=int(np.sqrt(len(edge_removals))));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewiring plots and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T19:53:05.377555Z",
     "start_time": "2022-05-15T19:53:05.229691Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_rewiring(modelo, loader, device): #get rewired adjacency from one graph (pass batch)\n",
    "    test_predictions = []\n",
    "    test_labels = []\n",
    "    modelo.eval()\n",
    "    correct = 0\n",
    "    for i,data in enumerate(loader):\n",
    "        data = data.to(device)\n",
    "        pred, mc_loss, o_loss = modelo(data.x, data.edge_index, data.batch)\n",
    "        loss = F.nll_loss(pred, data.y.view(-1)) + mc_loss + o_loss\n",
    "        \n",
    "        correct += pred.max(dim=1)[1].eq(data.y.view(-1)).sum().item()\n",
    "        test_predictions.extend(pred.max(dim=1)[1].tolist())\n",
    "        test_labels.extend(data.y.detach().cpu().numpy())\n",
    "        \n",
    "        print(modelo.new_adj.shape)\n",
    "        if i == 0:\n",
    "            test_adj = modelo.new_adj\n",
    "        else:\n",
    "            pass\n",
    "            #test_adj = torch.cat((test_adj,modelo.new_adj.detach()), 0)\n",
    "        \n",
    "        #print(modelo.emb.shape)\n",
    "    return loss.detach().cpu(), correct/len(test_labels), test_adj, test_labels, test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T19:53:06.298100Z",
     "start_time": "2022-05-15T19:53:06.127551Z"
    }
   },
   "outputs": [],
   "source": [
    "model =  CTNet_adj_rw(dataset.num_features, dataset.num_classes, k_centers=num_of_centers).to(device)\n",
    "model.load_state_dict(torch.load(modelito, map_location=torch.device(device)))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sacamos rewire del batch que queramos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T19:53:07.292442Z",
     "start_time": "2022-05-15T19:53:07.120901Z"
    }
   },
   "outputs": [],
   "source": [
    "loss, acc, adj_rw, test_labels, test_predictions = test_rewiring(model, [next(iter(loader))], device)\n",
    "adj_rw = adj_rw.detach().cpu()\n",
    "print('ADJ shape:',adj_rw.shape, adj_rw.device)\n",
    "print('Dataset size:',len(test_predictions))\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T19:53:08.198213Z",
     "start_time": "2022-05-15T19:53:08.042470Z"
    }
   },
   "outputs": [],
   "source": [
    "p = np.array(test_predictions)\n",
    "l = np.array(test_labels)\n",
    "print('Acc:',(np.sum(p == l)/len(p))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miramos donde ha acertado"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T18:57:07.544451Z",
     "start_time": "2022-05-15T18:57:07.421779Z"
    }
   },
   "source": [
    "np.where(p == l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo pasamos a nodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:19:12.179100Z",
     "start_time": "2022-05-15T20:19:12.041961Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage of removed and added graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T19:57:27.031548Z",
     "start_time": "2022-05-15T19:57:26.909856Z"
    }
   },
   "outputs": [],
   "source": [
    "def diff_adj(adj1, adj2):\n",
    "    assert adj1.shape == adj2.shape\n",
    "    added = 0\n",
    "    removed = 0\n",
    "    mantained = 0\n",
    "    original = np.count_nonzero(adj1)\n",
    "    for i in range(adj1.shape[0]):\n",
    "        for j in range(adj1.shape[1]):\n",
    "            \n",
    "            if adj1[i,j]==1 and adj2[i,j]==0:\n",
    "                removed+=1\n",
    "                \n",
    "            elif adj1[i,j]==0 and adj2[i,j]==1:\n",
    "                added+=1\n",
    "            elif adj1[i,j]==1 and adj2[i,j]==1:\n",
    "                mantained+=1\n",
    "                \n",
    "    return added, removed, mantained, original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T19:57:27.932143Z",
     "start_time": "2022-05-15T19:57:27.779551Z"
    }
   },
   "outputs": [],
   "source": [
    "eps=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T19:57:28.847041Z",
     "start_time": "2022-05-15T19:57:28.692507Z"
    }
   },
   "outputs": [],
   "source": [
    "adj_rw[adj_rw<eps] = 0\n",
    "adj_rw[adj_rw!=0] = 1\n",
    "adj_rw.shape, np.count_nonzero(adj_rw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T19:57:29.800003Z",
     "start_time": "2022-05-15T19:57:29.612995Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_original_adj = to_dense_adj(next(iter(loader)).edge_index, next(iter(loader)).batch)\n",
    "batch_original_adj.shape, np.count_nonzero(batch_original_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T19:57:30.749979Z",
     "start_time": "2022-05-15T19:57:30.597870Z"
    }
   },
   "outputs": [],
   "source": [
    "np.count_nonzero(batch_original_adj[0]), np.count_nonzero(adj_rw[0])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:07:22.942813Z",
     "start_time": "2022-05-15T20:07:22.793949Z"
    }
   },
   "outputs": [],
   "source": [
    "added, removed, mantained, original = diff_adj(batch_original_adj[5], adj_rw[5])\n",
    "added, removed, mantained, original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:07:23.860364Z",
     "start_time": "2022-05-15T20:07:23.706772Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "original2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:09:05.647233Z",
     "start_time": "2022-05-15T20:09:05.518458Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:09:13.819742Z",
     "start_time": "2022-05-15T20:09:13.690037Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:09:29.213005Z",
     "start_time": "2022-05-15T20:09:29.099087Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T20:06:11.391160Z",
     "start_time": "2022-05-15T20:06:11.266477Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T19:33:04.072485Z",
     "start_time": "2022-05-15T19:33:03.938833Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T19:36:55.047189Z",
     "start_time": "2022-05-15T19:36:54.919506Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver solo uno - Recableado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T18:33:54.182979Z",
     "start_time": "2022-05-15T18:33:54.022010Z"
    }
   },
   "outputs": [],
   "source": [
    "dense_to_sparse(adj_rw.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All graphs embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings GapNet Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T10:36:16.190430Z",
     "start_time": "2022-05-15T10:36:16.190430Z"
    }
   },
   "outputs": [],
   "source": [
    "test_loader =  DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T10:36:16.192426Z",
     "start_time": "2022-05-15T10:36:16.192426Z"
    }
   },
   "outputs": [],
   "source": [
    "test_loader =  DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "model =  GAPNet(dataset.num_features, dataset.num_classes, derivative=\"laplacian\",device=device)\n",
    "model.load_state_dict(torch.load(\"models/REDDIT-BINARY_GAPNet_laplacian_iter0.pth\", map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical data about the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T10:36:16.193420Z",
     "start_time": "2022-05-15T10:36:16.193420Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric import utils\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "nxdata = {\n",
    "    'Assortativity':np.empty(len(dataset)),\n",
    "    'Triangles':np.empty(len(dataset)),\n",
    "    'Transitivity':np.empty(len(dataset)),\n",
    "    'Clustering':np.empty(len(dataset))\n",
    "}\n",
    "for i, graph in enumerate(tqdm(dataset, desc='Datasets')):\n",
    "    G = utils.to_networkx(graph, to_undirected=True)\n",
    "    nxdata['Assortativity'][i] = nx.degree_assortativity_coefficient(G)\n",
    "    nxdata['Triangles'][i] = np.sum(list(nx.triangles(G).values()))/3\n",
    "    nxdata['Transitivity'][i] = nx.transitivity(G)\n",
    "    nxdata['Clustering'][i] = nx.average_clustering(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T10:36:16.195418Z",
     "start_time": "2022-05-15T10:36:16.195418Z"
    }
   },
   "outputs": [],
   "source": [
    "for k in nxdata:\n",
    "    print(f\"{k}: {nxdata[k].mean():.4f} +- {nxdata[k].std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-14T19:12:53.435551Z",
     "start_time": "2022-05-14T19:12:53.310028Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T10:36:16.196416Z",
     "start_time": "2022-05-15T10:36:16.196416Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def class_distrib(dataset):\n",
    "    d = dict()\n",
    "    for data in dataset:\n",
    "        d[int(data.y.numpy())] = d.get(int(data.y.numpy()),0) + 1\n",
    "    return d\n",
    "\n",
    "def batch_class_distrib(batch):\n",
    "    d = dict()\n",
    "    for label in batch.y:\n",
    "        d[int(label.numpy())] = d.get(int(label.numpy()),0) + 1\n",
    "    return d\n",
    "\n",
    "len(dataset.data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T10:36:16.198410Z",
     "start_time": "2022-05-15T10:36:16.198410Z"
    }
   },
   "outputs": [],
   "source": [
    "train_indices, val_indices = train_test_split(list(range(len(dataset.data.y))), test_size=0.2, stratify=dataset.data.y)\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T10:36:16.200401Z",
     "start_time": "2022-05-15T10:36:16.200401Z"
    }
   },
   "outputs": [],
   "source": [
    "class_distrib(dataset), class_distrib(train_dataset), class_distrib(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T10:36:16.202396Z",
     "start_time": "2022-05-15T10:36:16.202396Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T10:36:16.203394Z",
     "start_time": "2022-05-15T10:36:16.203394Z"
    }
   },
   "outputs": [],
   "source": [
    "class StratifiedSampler():\n",
    "    \"\"\"Stratified Sampling\n",
    "    Provides equal representation of target classes in each batch\n",
    "    \"\"\"\n",
    "    def __init__(self, class_vector, batch_size):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        class_vector : torch tensor\n",
    "            a vector of class labels\n",
    "        batch_size : integer\n",
    "            batch_size\n",
    "        \"\"\"\n",
    "        self.n_splits = int(class_vector.size(0) / batch_size)\n",
    "        self.class_vector = class_vector\n",
    "\n",
    "    def gen_sample_array(self):\n",
    "        try:\n",
    "            from sklearn.model_selection import StratifiedShuffleSplit\n",
    "        except:\n",
    "            print('Need scikit-learn for this functionality')\n",
    "        import numpy as np\n",
    "        \n",
    "        s = StratifiedShuffleSplit(n_splits=self.n_splits, test_size=0.5)\n",
    "        X = torch.randn(self.class_vector.size(0),2).numpy()\n",
    "        y = self.class_vector.numpy()\n",
    "        s.get_n_splits(X, y)\n",
    "\n",
    "        train_index, test_index = next(s.split(X, y))\n",
    "        return np.hstack([train_index, test_index])\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.gen_sample_array())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.class_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T10:36:16.205389Z",
     "start_time": "2022-05-15T10:36:16.205389Z"
    }
   },
   "outputs": [],
   "source": [
    "sampler = StratifiedSampler(class_vector=dataset.data.y, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T10:36:16.207383Z",
     "start_time": "2022-05-15T10:36:16.207383Z"
    }
   },
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=2, #train_dataset\n",
    "                        shuffle=False, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIGL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T10:36:16.208381Z",
     "start_time": "2022-05-15T10:36:16.208381Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from torch_geometric.utils.convert import to_scipy_sparse_matrix, from_scipy_sparse_matrix\n",
    "from torch_geometric.utils import dense_to_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T10:36:16.210400Z",
     "start_time": "2022-05-15T10:36:16.210400Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import BaseTransform\n",
    "\n",
    "class DIGLedges(BaseTransform):\n",
    "    def __init__(self, alpha:float, eps:float, use_edge_weigths = False):\n",
    "        self.alpha = alpha\n",
    "        self.eps = eps\n",
    "        self.use_edge_weigths = use_edge_weigths\n",
    "\n",
    "    def __call__(self, data):\n",
    "        new_edges, new_weights = self.digl_edges(data.edge_index, self.alpha, self.eps)\n",
    "        data.edge_index = new_edges\n",
    "        \n",
    "        if self.use_edge_weigths:\n",
    "            data.edge_weight = new_weights\n",
    "            \n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def gdc(self, A: sp.csr_matrix, alpha: float, eps: float):\n",
    "        N = A.shape[0]\n",
    "\n",
    "        # Self-loops\n",
    "        A_loop = sp.eye(N) + A\n",
    "\n",
    "        # Symmetric transition matrix\n",
    "        D_loop_vec = A_loop.sum(0).A1\n",
    "        D_loop_vec_invsqrt = 1 / np.sqrt(D_loop_vec)\n",
    "        D_loop_invsqrt = sp.diags(D_loop_vec_invsqrt)\n",
    "        T_sym = D_loop_invsqrt @ A_loop @ D_loop_invsqrt\n",
    "\n",
    "        # PPR-based diffusion\n",
    "        S = alpha * sp.linalg.inv(sp.eye(N) - (1 - alpha) * T_sym)\n",
    "\n",
    "        # Sparsify using threshold epsilon\n",
    "        S_tilde = S.multiply(S >= eps)\n",
    "\n",
    "        # Column-normalized transition matrix on graph S_tilde\n",
    "        D_tilde_vec = S_tilde.sum(0).A1\n",
    "        T_S = S_tilde / D_tilde_vec\n",
    "\n",
    "        return T_S\n",
    "\n",
    "    def digl_edges(self, edges, alpha, eps):\n",
    "        A0 = sp.csr_matrix(to_scipy_sparse_matrix(edges))\n",
    "        new_sp_matrix = sp.csr_matrix(gdc(A0, self.alpha, self.eps))\n",
    "        new_edge_index, weights = from_scipy_sparse_matrix(new_sp_matrix)\n",
    "        return new_edge_index, weights\n",
    "    \n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.__class__.__name__}({self.alpha})'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T10:36:16.212370Z",
     "start_time": "2022-05-15T10:36:16.212370Z"
    }
   },
   "outputs": [],
   "source": [
    "digl_data = TUDataset(root='data/digl/TUDataset',name='MUTAG', transform=DIGLedges(0.5, 0.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T10:36:16.214367Z",
     "start_time": "2022-05-15T10:36:16.214367Z"
    }
   },
   "outputs": [],
   "source": [
    "digl_data[0].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T10:36:16.216359Z",
     "start_time": "2022-05-15T10:36:16.216359Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[0].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T10:36:16.217356Z",
     "start_time": "2022-05-15T10:36:16.217356Z"
    }
   },
   "outputs": [],
   "source": [
    "digl_data = TUDataset(root='data/digl/TUDataset',name='MUTAG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T10:36:16.219355Z",
     "start_time": "2022-05-15T10:36:16.219355Z"
    }
   },
   "outputs": [],
   "source": [
    "digl_data[0].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T16:54:40.496948Z",
     "start_time": "2022-05-15T16:54:40.467650Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "table_dict_acc = dict()\n",
    "table_dict_std = dict()\n",
    "for file in os.listdir('logs_stratified'):\n",
    "    data, model, *_ = file.split('_')\n",
    "    \n",
    "    f = open('logs_stratified/' + file, 'r')\n",
    "    for last_line in f:\n",
    "        pass\n",
    "    \n",
    "    result = last_line.split()\n",
    "    if data not in table_dict_acc:\n",
    "        table_dict_acc[data]=dict()\n",
    "        table_dict_std[data]=dict()\n",
    "    try:\n",
    "        acc = float(result[0])\n",
    "        std = float(result[-1])\n",
    "        table_dict_acc[data][model]=acc\n",
    "        table_dict_std[data][model]=std\n",
    "    except:\n",
    "        print(model, data, \"FAIL\")\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "pd.DataFrame(table_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T16:55:41.768584Z",
     "start_time": "2022-05-15T16:55:41.760194Z"
    }
   },
   "outputs": [],
   "source": [
    "df_acc= pd.DataFrame(table_dict_acc).sort_index(ascending=True)*100\n",
    "df_std= pd.DataFrame(table_dict_std).sort_index(ascending=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T17:08:41.136350Z",
     "start_time": "2022-05-15T17:08:41.117497Z"
    }
   },
   "outputs": [],
   "source": [
    "df_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T17:08:48.345680Z",
     "start_time": "2022-05-15T17:08:48.335060Z"
    }
   },
   "outputs": [],
   "source": [
    "df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T17:33:45.848796Z",
     "start_time": "2022-05-15T17:33:45.839501Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'{\"\":>11}', end='&')\n",
    "for dataset in df_acc.columns:\n",
    "    print(f'{dataset:>17}', end=' &')\n",
    "print()\n",
    "for model, values in df_acc.iterrows():\n",
    "    print(f'{model:>10}', end=' & ')\n",
    "    for dataset in values.index:\n",
    "        print(f'${values[dataset]:>5.2f} \\\\pm {df_std.loc[model, dataset]:>4.2f}$', end=' & ')\n",
    "    print(r'\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T17:46:22.384379Z",
     "start_time": "2022-05-15T17:46:22.238673Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch_geometric import utils\n",
    "import networkx as nx\n",
    "from community import community_louvain, generate_dendrogram, partition_at_level\n",
    "\n",
    "def community_layout(g, partition):\n",
    "    \"\"\"\n",
    "    Compute the layout for a modular graph.\n",
    "\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "    g -- networkx.Graph or networkx.DiGraph instance\n",
    "        graph to plot\n",
    "\n",
    "    partition -- dict mapping int node -> int community\n",
    "        graph partitions\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pos -- dict mapping int node -> (float x, float y)\n",
    "        node positions\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    pos_communities = _position_communities(g, partition, scale=3.)\n",
    "\n",
    "    pos_nodes = _position_nodes(g, partition, scale=1.)\n",
    "\n",
    "    # combine positions\n",
    "    pos = dict()\n",
    "    for node in g.nodes():\n",
    "        pos[node] = pos_communities[node] + pos_nodes[node]\n",
    "\n",
    "    return pos\n",
    "\n",
    "def _position_communities(g, partition, **kwargs):\n",
    "\n",
    "    # create a weighted graph, in which each node corresponds to a community,\n",
    "    # and each edge weight to the number of edges between communities\n",
    "    between_community_edges = _find_between_community_edges(g, partition)\n",
    "\n",
    "    communities = set(partition.values())\n",
    "    hypergraph = nx.DiGraph()\n",
    "    hypergraph.add_nodes_from(communities)\n",
    "    for (ci, cj), edges in between_community_edges.items():\n",
    "        hypergraph.add_edge(ci, cj, weight=len(edges))\n",
    "\n",
    "    # find layout for communities\n",
    "    pos_communities = nx.spring_layout(hypergraph, **kwargs)\n",
    "\n",
    "    # set node positions to position of community\n",
    "    pos = dict()\n",
    "    for node, community in partition.items():\n",
    "        pos[node] = pos_communities[community]\n",
    "\n",
    "    return pos\n",
    "\n",
    "def _find_between_community_edges(g, partition):\n",
    "\n",
    "    edges = dict()\n",
    "\n",
    "    for (ni, nj) in g.edges():\n",
    "        ci = partition[ni]\n",
    "        cj = partition[nj]\n",
    "\n",
    "        if ci != cj:\n",
    "            try:\n",
    "                edges[(ci, cj)] += [(ni, nj)]\n",
    "            except KeyError:\n",
    "                edges[(ci, cj)] = [(ni, nj)]\n",
    "\n",
    "    return edges\n",
    "\n",
    "def _position_nodes(g, partition, **kwargs):\n",
    "    \"\"\"\n",
    "    Positions nodes within communities.\n",
    "    \"\"\"\n",
    "\n",
    "    communities = dict()\n",
    "    for node, community in partition.items():\n",
    "        try:\n",
    "            communities[community] += [node]\n",
    "        except KeyError:\n",
    "            communities[community] = [node]\n",
    "\n",
    "    pos = dict()\n",
    "    for ci, nodes in communities.items():\n",
    "        subgraph = g.subgraph(nodes)\n",
    "        pos_subgraph = nx.spring_layout(subgraph, **kwargs)\n",
    "        pos.update(pos_subgraph)\n",
    "\n",
    "    return pos\n",
    "\n",
    "def test():\n",
    "    # to install networkx 2.0 compatible version of python-louvain use:\n",
    "    # pip install -U git+https://github.com/taynaud/python-louvain.git@networkx2\n",
    "    from community import community_louvain\n",
    "\n",
    "    g = nx.karate_club_graph()\n",
    "    \n",
    "    dendrogram = generate_dendrogram(g)\n",
    "    partition = partition_at_level(dendrogram, len(dendrogram) - 1)\n",
    "    \n",
    "    #partition = community_louvain.best_partition(g)\n",
    "    pos = community_layout(g, partition)\n",
    "\n",
    "    nx.draw(g, pos, node_color=list(partition.values())); plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T17:46:22.977344Z",
     "start_time": "2022-05-15T17:46:22.767412Z"
    }
   },
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T17:46:56.777519Z",
     "start_time": "2022-05-15T17:46:56.654758Z"
    }
   },
   "outputs": [],
   "source": [
    "G = utils.to_networkx(dataset[20], to_undirected=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T17:46:57.480746Z",
     "start_time": "2022-05-15T17:46:57.176298Z"
    }
   },
   "outputs": [],
   "source": [
    "partition = community_louvain.best_partition(G)\n",
    "pos = community_layout(G, partition)\n",
    "nx.draw(G, pos, node_color=list(partition.values())); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/43541376/how-to-draw-communities-with-networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T17:59:00.753144Z",
     "start_time": "2022-05-15T17:59:00.619499Z"
    }
   },
   "outputs": [],
   "source": [
    "np.array(cmap(3)).reshape(1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T17:58:23.550993Z",
     "start_time": "2022-05-15T17:58:23.420375Z"
    }
   },
   "outputs": [],
   "source": [
    "cmap = cm.get_cmap('Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T17:58:34.181389Z",
     "start_time": "2022-05-15T17:58:34.041581Z"
    }
   },
   "outputs": [],
   "source": [
    "cmap(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T17:59:55.706206Z",
     "start_time": "2022-05-15T17:59:55.573333Z"
    }
   },
   "outputs": [],
   "source": [
    "node_color = {node: cmap(community_id) for node, community_id in partition.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T18:00:02.384887Z",
     "start_time": "2022-05-15T18:00:02.227272Z"
    }
   },
   "outputs": [],
   "source": [
    "node_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T17:51:01.949042Z",
     "start_time": "2022-05-15T17:51:01.777870Z"
    }
   },
   "outputs": [],
   "source": [
    "from netgraph import Graph\n",
    "# https://netgraph.readthedocs.io/en/latest/graph_classes.html#netgraph.Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-15T18:00:56.351727Z",
     "start_time": "2022-05-15T18:00:32.388183Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "Graph(G, node_color=node_color,node_size=1,\n",
    "      node_edge_width=0, edge_alpha=0.1,\n",
    "      node_layout='community', node_layout_kwargs=dict(node_to_community=partition),\n",
    "      edge_layout='bundled', edge_layout_kwargs=dict(k=2000),\n",
    ") # edge_cmap!!!!! #edge_color\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f24d556599f9bcb6882e345745e2df8a56c1b9eae44969deb7bb16a44466b46"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Table of Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
