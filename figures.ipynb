{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mvrlab/miniconda3/envs/pg/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from nets import CTNet, GAPNet\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "from transform_features import FeatureDegree\n",
    "from torch_geometric.datasets import TUDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(modelo, loader, device):\n",
    "    modelo.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        pred, mc_loss, o_loss = modelo(data.x, data.edge_index, data.batch)\n",
    "        loss = F.nll_loss(pred, data.y.view(-1)) + mc_loss + o_loss\n",
    "        correct += pred.max(dim=1)[1].eq(data.y.view(-1)).sum().item()\n",
    "\n",
    "    return loss, correct / len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUDataset(root='data_colab/TUDataset',name=\"REDDIT-BINARY\", pre_transform=FeatureDegree(), use_node_attr=True)\n",
    "BATCH_SIZE = 64\n",
    "num_of_centers = 420\n",
    "\n",
    "dataset = TUDataset(root='data_colab/TUDataset',name=\"MUTAG\")\n",
    "BATCH_SIZE = 32\n",
    "num_of_centers = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: MUTAG(188):\n",
      "====================\n",
      "Number of graphs: 188\n",
      "Number of features: 7, 7, 0\n",
      "Number of classes: 2\n",
      "\n",
      "Data(edge_index=[2, 38], x=[17, 7], edge_attr=[38, 4], y=[1])\n",
      "=============================================================\n",
      "Number of nodes: 17\n",
      "Number of edges: 38\n",
      "Average node degree: 2.24\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n",
      "MUTAG(188)\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}, {dataset.num_node_features}, {dataset.num_node_attributes}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "print()\n",
    "datum = dataset[0]  # Get the first graph object.\n",
    "print(datum)\n",
    "print('=============================================================')\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {datum.num_nodes}')\n",
    "print(f'Number of edges: {datum.num_edges}')\n",
    "print(f'Average node degree: {datum.num_edges / datum.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {datum.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {datum.has_self_loops()}')\n",
    "print(f'Is undirected: {datum.is_undirected()}')\n",
    "\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.36352052393546647, 0.1747312785712479)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings CTNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader =  DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CTNet(\n",
       "  (conv1): DenseGraphConv(32, 32)\n",
       "  (conv2): DenseGraphConv(32, 32)\n",
       "  (pool1): Linear(in_features=32, out_features=420, bias=True)\n",
       "  (pool2): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (lin1): Linear(in_features=1, out_features=32, bias=True)\n",
       "  (lin2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (lin3): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Epoch: 059, Train Loss: 165.455, Train Acc: 0.711, Test Loss: 150.841, Test Acc: 0.750\n",
    "model =  CTNet(dataset.num_features, dataset.num_classes, k_centers=num_of_centers).to(device)\n",
    "model.load_state_dict(torch.load(\"models/REDDIT-BINARY_CTNet_iter0.pth\", map_location=torch.device(device)))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0622), 0.794)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings GapNet Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader =  DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader =  DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "model =  GAPNet(dataset.num_features, dataset.num_classes, derivative=\"laplacian\",device=device)\n",
    "model.load_state_dict(torch.load(\"models/REDDIT-BINARY_GAPNet_laplacian_iter0.pth\", map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Degree assortativity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from torch_geometric import utils\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "d_assortativities = np.empty(len(dataset))\n",
    "for i, graph in enumerate(dataset):\n",
    "    G = utils.to_networkx(graph, to_undirected=True)\n",
    "    d_assortativities[i] = nx.degree_assortativity_coefficient(G)\n",
    "d_assortativities.mean(), d_assortativities.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def class_distrib(dataset):\n",
    "    d = dict()\n",
    "    for data in dataset:\n",
    "        d[int(data.y.numpy())] = d.get(int(data.y.numpy()),0) + 1\n",
    "    return d\n",
    "\n",
    "def batch_class_distrib(batch):\n",
    "    d = dict()\n",
    "    for label in batch.y:\n",
    "        d[int(label.numpy())] = d.get(int(label.numpy()),0) + 1\n",
    "    return d\n",
    "\n",
    "len(dataset.data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, val_indices = train_test_split(list(range(len(dataset.data.y))), test_size=0.2, stratify=dataset.data.y)\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "val_dataset = torch.utils.data.Subset(dataset, val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({5: 100, 4: 100, 0: 100, 1: 100, 2: 100, 3: 100},\n",
       " {0: 80, 5: 80, 4: 80, 1: 80, 2: 80, 3: 80},\n",
       " {0: 20, 1: 20, 3: 20, 5: 20, 4: 20, 2: 20})"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_distrib(dataset), class_distrib(train_dataset), class_distrib(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StratifiedSampler():\n",
    "    \"\"\"Stratified Sampling\n",
    "    Provides equal representation of target classes in each batch\n",
    "    \"\"\"\n",
    "    def __init__(self, class_vector, batch_size):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        class_vector : torch tensor\n",
    "            a vector of class labels\n",
    "        batch_size : integer\n",
    "            batch_size\n",
    "        \"\"\"\n",
    "        self.n_splits = int(class_vector.size(0) / batch_size)\n",
    "        self.class_vector = class_vector\n",
    "\n",
    "    def gen_sample_array(self):\n",
    "        try:\n",
    "            from sklearn.model_selection import StratifiedShuffleSplit\n",
    "        except:\n",
    "            print('Need scikit-learn for this functionality')\n",
    "        import numpy as np\n",
    "        \n",
    "        s = StratifiedShuffleSplit(n_splits=self.n_splits, test_size=0.5)\n",
    "        X = torch.randn(self.class_vector.size(0),2).numpy()\n",
    "        y = self.class_vector.numpy()\n",
    "        s.get_n_splits(X, y)\n",
    "\n",
    "        train_index, test_index = next(s.split(X, y))\n",
    "        return np.hstack([train_index, test_index])\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.gen_sample_array())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.class_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = StratifiedSampler(class_vector=dataset.data.y, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, #train_dataset\n",
    "                        shuffle=False, sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 9, 1: 19}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "npocha = [0.638, 0.788, 0.65, 0.82, 0.816, 0.83, 0.772, 0.704, 0.8, 0.696]\n",
    "n = [0.76, 0.84, 0.624, 0.614, 0.768, 0.776, 0.836, 0.776, 0.706, 0.71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7514, 0.06902202547013525)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(npocha), np.std(npocha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7409999999999999, 0.0737360156233031)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(n), np.std(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f24d556599f9bcb6882e345745e2df8a56c1b9eae44969deb7bb16a44466b46"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
